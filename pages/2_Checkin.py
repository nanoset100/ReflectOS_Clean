"""
ReflectOS - Check-in
ì¼ìƒ ê¸°ë¡ ì…ë ¥ (í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±)
Step 2: ê·œì¹™ ê¸°ë°˜ ì¶”ì¶œ
Step 3: LLM ê¸°ë°˜ êµ¬ì¡°í™” (Extractor)
Step 4: ìŒì„± STT
Step 5: ì´ë¯¸ì§€ Vision
"""
import streamlit as st
import re
from typing import Dict, List, Optional
from datetime import datetime

st.set_page_config(page_title="Check-in - ReflectOS", page_icon="âœï¸", layout="wide")


# === ìë™ ì¸ë±ì‹± í† ê¸€ ê°’ ë¡œë“œ ===
from lib.supabase_db import get_profile
_profile = get_profile()
_settings = (_profile or {}).get("settings") or {}
if "auto_index_on_save" not in st.session_state:
    st.session_state["auto_index_on_save"] = bool(_settings.get("auto_index_on_save", False))


# === ê·œì¹™ ê¸°ë°˜ Extraction (í´ë°±ìš©) ===
def extract_by_rules(content: str) -> Dict[str, List[str]]:
    """
    ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ í…ìŠ¤íŠ¸ì—ì„œ êµ¬ì¡°í™”ëœ ì •ë³´ ì¶”ì¶œ
    """
    lines = content.strip().split('\n')
    
    tasks = []
    obstacles = []
    projects = []
    insights = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # task: '-' ë˜ëŠ” 'â€¢'ë¡œ ì‹œì‘í•˜ëŠ” ì¤„
        if line.startswith('-') or line.startswith('â€¢') or line.startswith('*'):
            task_text = line.lstrip('-â€¢* ').strip()
            if task_text:
                tasks.append(task_text)
        
        # obstacle: '!' ì‹œì‘ ë˜ëŠ” ë¶€ì •ì  í‚¤ì›Œë“œ í¬í•¨
        obstacle_keywords = ['ë¬¸ì œ', 'ì–´ë ¤ì›€', 'í˜ë“¤', 'ë§‰í˜€', 'ì•ˆë¨', 'ì‹¤íŒ¨', 'ì˜¤ë¥˜', 'ë²„ê·¸']
        if line.startswith('!') or any(kw in line for kw in obstacle_keywords):
            obstacle_text = line.lstrip('! ').strip()
            if obstacle_text and obstacle_text not in obstacles:
                obstacles.append(obstacle_text)
        
        # project: '#í”„ë¡œì íŠ¸ëª…' í˜•íƒœ
        project_matches = re.findall(r'#(\w+)', line)
        for proj in project_matches:
            if proj not in projects:
                projects.append(proj)
        
        # insight: ì¸ì‚¬ì´íŠ¸ í‚¤ì›Œë“œ í¬í•¨
        insight_keywords = ['ğŸ’¡', 'ì¸ì‚¬ì´íŠ¸', 'ë°°ì›€', 'ê¹¨ë‹¬ìŒ', 'ë°œê²¬', 'ì•„ì´ë””ì–´']
        if any(kw in line for kw in insight_keywords):
            insight_text = line.strip()
            if insight_text and insight_text not in insights:
                insights.append(insight_text)
    
    return {
        "tasks": tasks,
        "obstacles": obstacles,
        "projects": projects,
        "insights": insights,
        "people": [],
        "emotions": []
    }


st.title("âœï¸ Check-in")
st.caption("ì˜¤ëŠ˜ì˜ ìƒê°ê³¼ ê°ì •ì„ ê¸°ë¡í•˜ì„¸ìš”")

# === ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ===
if "transcribed_text" not in st.session_state:
    st.session_state.transcribed_text = ""
if "image_analysis" not in st.session_state:
    st.session_state.image_analysis = ""
if "uploaded_artifacts" not in st.session_state:
    st.session_state.uploaded_artifacts = []  # [{type, storage_path, metadata}]

# === ì‚¬ì´ë“œë°”: AI ì„¤ì • ===
with st.sidebar:
    st.subheader("ğŸ¤– AI ì„¤ì •")
    use_ai_extraction = st.toggle(
        "LLM ê¸°ë°˜ êµ¬ì¡°í™” ì‚¬ìš©",
        value=True,
        help="OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•˜ê²Œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤"
    )
    
    if use_ai_extraction:
        use_ingestor = st.checkbox(
            "í…ìŠ¤íŠ¸ ì •ë¦¬ (Ingestor)",
            value=False,
            help="í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬/ì •ê·œí™”í•œ í›„ ë¶„ì„"
        )
        generate_reflection = st.checkbox(
            "AI ì½”ë©˜íŠ¸ ìƒì„±",
            value=True,
            help="ì²´í¬ì¸ì— ëŒ€í•œ ì§§ì€ AI ì½”ë©˜íŠ¸"
        )
    else:
        use_ingestor = False
        generate_reflection = False
    
    st.divider()
    st.caption("ğŸ’¡ LLM ë¯¸ì‚¬ìš© ì‹œ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ")


# === ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ì„¹ì…˜ (Step 4, 5) ===
st.subheader("ğŸ™ï¸ ë©€í‹°ëª¨ë‹¬ ì…ë ¥")

tab_audio, tab_image = st.tabs(["ğŸ¤ ìŒì„± ì…ë ¥", "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì…ë ¥"])

# --- ìŒì„± ì…ë ¥ íƒ­ (Step 4) ---
with tab_audio:
    st.markdown("**ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤**")
    
    audio_file = st.file_uploader(
        "ìŒì„± íŒŒì¼ ì„ íƒ",
        type=["mp3", "wav", "m4a", "ogg", "webm"],
        key="audio_uploader",
        help="ì§€ì› í˜•ì‹: MP3, WAV, M4A, OGG, WebM"
    )
    
    if audio_file is not None:
        # ì˜¤ë””ì˜¤ ë¯¸ë¦¬ë³´ê¸°
        st.audio(audio_file, format=f"audio/{audio_file.type.split('/')[-1]}")
        
        if st.button("ğŸ¯ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜", key="transcribe_btn"):
            with st.spinner("ğŸ”„ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘..."):
                try:
                    from lib.openai_client import transcribe_audio
                    from lib.supabase_storage import upload_file
                    from lib.supabase_db import insert_artifact
                    
                    # 1. Supabase Storageì— ì—…ë¡œë“œ
                    file_bytes = audio_file.getvalue()
                    content_type = audio_file.type or "audio/mpeg"
                    
                    storage_path = upload_file(
                        file_data=file_bytes,
                        file_name=audio_file.name,
                        content_type=content_type,
                        folder="audio"
                    )
                    
                    # 2. OpenAI Whisperë¡œ ì „ì‚¬
                    audio_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    transcribed = transcribe_audio(audio_file, language="ko")
                    
                    if transcribed:
                        st.session_state.transcribed_text = transcribed
                        
                        # artifacts ì •ë³´ ì €ì¥ (ì²´í¬ì¸ ì €ì¥ ì‹œ DBì— ê¸°ë¡)
                        st.session_state.uploaded_artifacts.append({
                            "type": "audio",
                            "storage_path": storage_path,
                            "original_name": audio_file.name,
                            "file_size": len(file_bytes),
                            "metadata": {
                                "transcription": transcribed,
                                "duration": None  # í–¥í›„ ì¶”ê°€ ê°€ëŠ¥
                            }
                        })
                        
                        st.success("âœ… ìŒì„± ë³€í™˜ ì™„ë£Œ!")
                    else:
                        st.error("ìŒì„± ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                except ImportError as e:
                    st.error(f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ì „ì‚¬ëœ í…ìŠ¤íŠ¸ í‘œì‹œ ë° í¸ì§‘
    if st.session_state.transcribed_text:
        st.markdown("---")
        st.markdown("**ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸** (í¸ì§‘ ê°€ëŠ¥)")
        edited_transcription = st.text_area(
            "ì „ì‚¬ ê²°ê³¼",
            value=st.session_state.transcribed_text,
            height=100,
            key="edit_transcription",
            label_visibility="collapsed"
        )
        st.session_state.transcribed_text = edited_transcription
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“‹ ë³¸ë¬¸ì— ì¶”ê°€", key="add_transcription"):
                st.session_state.add_to_content = st.session_state.transcribed_text
                st.success("ë³¸ë¬¸ì— ì¶”ê°€ë¨! ì•„ë˜ ë‚´ìš©ë€ì„ í™•ì¸í•˜ì„¸ìš”.")
        with col2:
            if st.button("ğŸ—‘ï¸ ì „ì‚¬ ë‚´ìš© ì‚­ì œ", key="clear_transcription"):
                st.session_state.transcribed_text = ""
                st.rerun()


# --- ì´ë¯¸ì§€ ì…ë ¥ íƒ­ (Step 5) ---
with tab_image:
    st.markdown("**ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ AIê°€ ë‚´ìš©ì„ ë¶„ì„í•©ë‹ˆë‹¤**")
    
    image_file = st.file_uploader(
        "ì´ë¯¸ì§€ íŒŒì¼ ì„ íƒ",
        type=["png", "jpg", "jpeg", "webp"],
        key="image_uploader",
        help="ì§€ì› í˜•ì‹: PNG, JPG, JPEG, WebP"
    )
    
    if image_file is not None:
        # ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
        st.image(image_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)
        
        if st.button("ğŸ” ì´ë¯¸ì§€ ë¶„ì„", key="analyze_image_btn"):
            with st.spinner("ğŸ”„ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                try:
                    from lib.openai_client import analyze_image
                    from lib.supabase_storage import upload_file, get_public_url
                    import base64
                    
                    # 1. Supabase Storageì— ì—…ë¡œë“œ
                    file_bytes = image_file.getvalue()
                    content_type = image_file.type or "image/jpeg"
                    
                    storage_path = upload_file(
                        file_data=file_bytes,
                        file_name=image_file.name,
                        content_type=content_type,
                        folder="images"
                    )
                    
                    # 2. Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ Vision API í˜¸ì¶œ
                    base64_image = base64.b64encode(file_bytes).decode('utf-8')
                    image_url = f"data:{content_type};base64,{base64_image}"
                    
                    # ë¶„ì„ í”„ë¡¬í”„íŠ¸
                    analysis_prompt = """ì´ ì´ë¯¸ì§€ì—ì„œ ë‹¤ìŒì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
1. ì´ë¯¸ì§€ì— ë³´ì´ëŠ” í…ìŠ¤íŠ¸/ë©”ëª¨ ë‚´ìš©
2. í•  ì¼ ëª©ë¡ì´ ìˆë‹¤ë©´ ì¶”ì¶œ
3. ì „ì²´ì ì¸ ë§¥ë½ ìš”ì•½ (í•œ ë¬¸ì¥)

ê°„ê²°í•˜ê²Œ ìš”ì ë§Œ ì •ë¦¬í•´ì£¼ì„¸ìš”."""
                    
                    analysis_result = analyze_image(image_url, analysis_prompt)
                    
                    if analysis_result:
                        st.session_state.image_analysis = analysis_result
                        
                        # artifacts ì •ë³´ ì €ì¥
                        st.session_state.uploaded_artifacts.append({
                            "type": "image",
                            "storage_path": storage_path,
                            "original_name": image_file.name,
                            "file_size": len(file_bytes),
                            "metadata": {
                                "analysis": analysis_result
                            }
                        })
                        
                        st.success("âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ!")
                    else:
                        st.error("ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                except ImportError as e:
                    st.error(f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                except Exception as e:
                    st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë¶„ì„ ê²°ê³¼ í‘œì‹œ ë° í¸ì§‘
    if st.session_state.image_analysis:
        st.markdown("---")
        st.markdown("**ğŸ“ ë¶„ì„ ê²°ê³¼** (í¸ì§‘ ê°€ëŠ¥)")
        edited_analysis = st.text_area(
            "ë¶„ì„ ê²°ê³¼",
            value=st.session_state.image_analysis,
            height=100,
            key="edit_analysis",
            label_visibility="collapsed"
        )
        st.session_state.image_analysis = edited_analysis
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“‹ ë³¸ë¬¸ì— ì¶”ê°€", key="add_analysis"):
                st.session_state.add_to_content = st.session_state.image_analysis
                st.success("ë³¸ë¬¸ì— ì¶”ê°€ë¨! ì•„ë˜ ë‚´ìš©ë€ì„ í™•ì¸í•˜ì„¸ìš”.")
        with col2:
            if st.button("ğŸ—‘ï¸ ë¶„ì„ ë‚´ìš© ì‚­ì œ", key="clear_analysis"):
                st.session_state.image_analysis = ""
                st.rerun()


st.divider()

# === ì²´í¬ì¸ í¼ ===
with st.form("checkin_form"):
    # ë¬´ë“œ ì„ íƒ
    st.subheader("ì˜¤ëŠ˜ ê¸°ë¶„ì€ ì–´ë–¤ê°€ìš”?")
    mood = st.radio(
        "ê¸°ë¶„ ì„ íƒ",
        options=["great", "good", "neutral", "bad", "terrible"],
        format_func=lambda x: {
            "great": "ğŸ˜Š ì•„ì£¼ ì¢‹ìŒ",
            "good": "ğŸ™‚ ì¢‹ìŒ",
            "neutral": "ğŸ˜ ë³´í†µ",
            "bad": "ğŸ˜” ì•ˆ ì¢‹ìŒ",
            "terrible": "ğŸ˜¢ ë§¤ìš° ì•ˆ ì¢‹ìŒ"
        }[x],
        horizontal=True,
        label_visibility="collapsed"
    )
    
    # ì—ë„ˆì§€ ìŠ¬ë¼ì´ë”
    st.subheader("âš¡ ì—ë„ˆì§€ ë ˆë²¨")
    energy = st.slider(
        "í˜„ì¬ ì—ë„ˆì§€ ë ˆë²¨",
        min_value=1,
        max_value=10,
        value=5,
        help="1: ë§¤ìš° ì§€ì¹¨ ~ 10: ì—ë„ˆì§€ ë„˜ì¹¨"
    )
    
    st.divider()
    
    # í…ìŠ¤íŠ¸ ì…ë ¥ (ë©€í‹°ëª¨ë‹¬ ê²°ê³¼ í•©ì¹˜ê¸°)
    st.subheader("ğŸ“ ë¬´ìŠ¨ ìƒê°ì„ í•˜ê³  ìˆë‚˜ìš”?")
    st.caption("ğŸ’¡ íŒ: `-`ë¡œ ì‹œì‘í•˜ë©´ í•  ì¼ë¡œ ì¶”ì¶œ, `#íƒœê·¸`ë¡œ í”„ë¡œì íŠ¸ ë¶„ë¥˜")
    
    # ë©€í‹°ëª¨ë‹¬ì—ì„œ ì¶”ê°€ëœ ë‚´ìš© í•©ì¹˜ê¸°
    initial_content = ""
    if hasattr(st.session_state, 'add_to_content') and st.session_state.add_to_content:
        initial_content = st.session_state.add_to_content + "\n\n"
        st.session_state.add_to_content = ""  # ë¦¬ì…‹
    
    content = st.text_area(
        "ë‚´ìš©",
        value=initial_content,
        placeholder="""ì˜¤ëŠ˜ ìˆì—ˆë˜ ì¼, ëŠë‚€ ì , ë°°ìš´ ê²ƒ ë“±ì„ ììœ ë¡­ê²Œ ì‘ì„±í•˜ì„¸ìš”...

ì˜ˆì‹œ:
- API ë¬¸ì„œ ì‘ì„± ì™„ë£Œ
- íšŒì˜ ì¤€ë¹„
#ReflectOS í”„ë¡œì íŠ¸ ì§„í–‰ ì¤‘
ğŸ’¡ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ í•˜ë‹ˆê¹Œ ì§‘ì¤‘ì´ ì˜ ë¨""",
        height=200,
        label_visibility="collapsed"
    )
    
    # íƒœê·¸ ì…ë ¥
    tags_input = st.text_input(
        "íƒœê·¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
        placeholder="ì˜ˆ: ì—…ë¬´, ê±´ê°•, ì•„ì´ë””ì–´",
    )
    
    st.divider()
    
    # ì œì¶œ ë²„íŠ¼
    submitted = st.form_submit_button("ğŸ’¾ ì €ì¥í•˜ê¸°", use_container_width=True, type="primary")
    
    if submitted:
        if not content.strip():
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        else:
            # íƒœê·¸ íŒŒì‹±
            tags = [t.strip() for t in tags_input.split(",") if t.strip()]
            
            # ë©€í‹°ëª¨ë‹¬ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            combined_content = content
            if st.session_state.transcribed_text:
                combined_content += f"\n\n[ğŸ¤ ìŒì„± ì „ì‚¬]\n{st.session_state.transcribed_text}"
            if st.session_state.image_analysis:
                combined_content += f"\n\n[ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„]\n{st.session_state.image_analysis}"
            
            # ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜
            extractions = None
            clean_text = combined_content
            ai_reflection = None
            extraction_type = "rule_based"
            
            # === AI ê¸°ë°˜ ì²˜ë¦¬ (Step 3) ===
            if use_ai_extraction:
                with st.spinner("ğŸ¤– AIê°€ ë¶„ì„ ì¤‘..."):
                    try:
                        from lib.openai_client import (
                            ingest_text, 
                            extract_structured_data,
                            generate_reflection as gen_reflection
                        )
                        
                        # Ingestor (ì„ íƒì )
                        if use_ingestor:
                            ingested = ingest_text(combined_content)
                            if ingested:
                                clean_text = ingested
                        
                        # Extractor (Structured Outputs)
                        llm_extractions = extract_structured_data(clean_text)
                        if llm_extractions:
                            extractions = llm_extractions
                            extraction_type = "llm_extractor"
                        
                        # Reflector (ì„ íƒì )
                        if generate_reflection:
                            ai_reflection = gen_reflection(clean_text)
                        
                    except ImportError as e:
                        st.warning(f"âš ï¸ OpenAI ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    except Exception as e:
                        st.warning(f"âš ï¸ AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ì²´): {e}")
            
            # === ê·œì¹™ ê¸°ë°˜ í´ë°± ===
            if extractions is None:
                extractions = extract_by_rules(combined_content)
                extraction_type = "rule_based"
            
            # === DB ì €ì¥ ===
            try:
                from lib.supabase_db import insert_checkin, insert_extraction, insert_artifact
                
                # ì²´í¬ì¸ ì €ì¥
                checkin_data = insert_checkin(
                    content=content,  # ì›ë³¸ í…ìŠ¤íŠ¸ë§Œ ì €ì¥
                    mood=mood,
                    tags=tags,
                    metadata={
                        "energy": energy,
                        "clean_text": clean_text if clean_text != content else None,
                        "has_audio": bool(st.session_state.transcribed_text),
                        "has_image": bool(st.session_state.image_analysis)
                    }
                )
                
                if checkin_data:
                    checkin_id = checkin_data.get("id")
                    
                    # artifacts ì €ì¥ (ë©€í‹°ëª¨ë‹¬)
                    for artifact in st.session_state.uploaded_artifacts:
                        insert_artifact(
                            checkin_id=checkin_id,
                            artifact_type=artifact["type"],
                            storage_path=artifact["storage_path"],
                            metadata=artifact.get("metadata"),
                            original_name=artifact.get("original_name"),
                            file_size=artifact.get("file_size")
                        )
                    
                    # extraction ì €ì¥
                    if any(extractions.values()):
                        insert_extraction(
                            source_type="checkin",
                            source_id=checkin_id,
                            extraction_type=extraction_type,
                            data=extractions
                        )
                    
                    st.success("âœ… ì²´í¬ì¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.balloons()
                    
                    # === ìë™ ì¸ë±ì‹± (í† ê¸€ ONì¼ ë•Œë§Œ) ===
                    if st.session_state.get("auto_index_on_save", False):
                        from lib.config import get_openai_api_key
                        if not get_openai_api_key():
                            st.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ì–´ ìë™ ì¸ë±ì‹±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
                        else:
                            with st.spinner("ğŸ§  ìë™ ì¸ë±ì‹± ì¤‘..."):
                                try:
                                    from lib.rag import index_checkin, index_extraction
                                    
                                    # checkin ì¸ë±ì‹±: clean_text ìš°ì„ (ë©€í‹°ëª¨ë‹¬/ingestor ë°˜ì˜)
                                    ok_checkin = index_checkin(checkin_id, clean_text, extractions)
                                    
                                    # extraction ì¸ë±ì‹±: ì¶”ì¶œê°’ì´ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ
                                    ok_extraction = True
                                    try:
                                        if extractions and any(extractions.values()):
                                            ok_extraction = index_extraction(checkin_id, extraction_type, extractions)
                                    except Exception:
                                        ok_extraction = False
                                    
                                    if ok_checkin and ok_extraction:
                                        st.info("âœ… ìë™ ì¸ë±ì‹± ì™„ë£Œ (Memoryì—ì„œ ì¦‰ì‹œ ê²€ìƒ‰ ê°€ëŠ¥)")
                                    else:
                                        st.warning("âš ï¸ ìë™ ì¸ë±ì‹± ì¼ë¶€ ì‹¤íŒ¨ (ì²´í¬ì¸ì€ ì €ì¥ë¨). í•„ìš”ì‹œ Memoryì—ì„œ ìˆ˜ë™ ë™ê¸°í™”í•˜ì„¸ìš”.")
                                except Exception as e:
                                    st.warning(f"âš ï¸ ìë™ ì¸ë±ì‹± ì˜¤ë¥˜ (ì²´í¬ì¸ì€ ì €ì¥ë¨): {e}")
                    
                    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                    st.session_state.transcribed_text = ""
                    st.session_state.image_analysis = ""
                    st.session_state.uploaded_artifacts = []
                    
                    # === ê²°ê³¼ í‘œì‹œ ===
                    with st.expander("ğŸ“‹ ì €ì¥ëœ ë‚´ìš© í™•ì¸", expanded=True):
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("**ê¸°ë³¸ ì •ë³´**")
                            st.json({
                                "mood": mood,
                                "energy": energy,
                                "tags": tags,
                                "extraction_type": extraction_type,
                                "artifacts_count": len(st.session_state.uploaded_artifacts) if st.session_state.uploaded_artifacts else 0
                            })
                        
                        with col2:
                            st.markdown(f"**ì¶”ì¶œëœ ì •ë³´** (`{extraction_type}`)")
                            
                            if extractions.get("tasks"):
                                st.markdown("**ğŸ“Œ Tasks:**")
                                for task in extractions["tasks"]:
                                    st.markdown(f"  - {task}")
                            
                            if extractions.get("obstacles"):
                                st.markdown("**âš ï¸ Obstacles:**")
                                for obs in extractions["obstacles"]:
                                    st.markdown(f"  - {obs}")
                            
                            if extractions.get("projects"):
                                st.markdown(f"**ğŸ“ Projects:** {', '.join(extractions['projects'])}")
                            
                            if extractions.get("insights"):
                                st.markdown("**ğŸ’¡ Insights:**")
                                for ins in extractions["insights"]:
                                    st.markdown(f"  - {ins}")
                            
                            if extractions.get("people"):
                                st.markdown(f"**ğŸ‘¥ People:** {', '.join(extractions['people'])}")
                            
                            if extractions.get("emotions"):
                                st.markdown(f"**ğŸ˜Š Emotions:** {', '.join(extractions['emotions'])}")
                            
                            if not any(extractions.values()):
                                st.caption("ì¶”ì¶œëœ í•­ëª© ì—†ìŒ")
                    
                    # AI ì½”ë©˜íŠ¸ í‘œì‹œ
                    if ai_reflection:
                        st.divider()
                        st.subheader("ğŸ’¬ AI ì½”ë©˜íŠ¸")
                        st.info(ai_reflection)
                else:
                    st.error("ì €ì¥ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    
            except ImportError as e:
                st.warning(f"âš ï¸ DB ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
                # ë°ëª¨ ëª¨ë“œ
                with st.expander("ì €ì¥ëœ ë‚´ìš© (ë°ëª¨)", expanded=True):
                    st.json({
                        "mood": mood,
                        "energy": energy,
                        "content": content[:100] + "...",
                        "tags": tags,
                        "extractions": extractions,
                        "extraction_type": extraction_type
                    })
                if ai_reflection:
                    st.info(f"ğŸ’¬ AI: {ai_reflection}")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
